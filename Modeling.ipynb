{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project - Starbucks app data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "b_session = boto3.session.Session(region_name='eu-central-1')\n",
    "\n",
    "session = sagemaker.Session(boto_session=b_session)\n",
    "role = 'AmazonSageMaker-ExecutionRole-20191105T072928'\n",
    "\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Data preprocessing\n",
    "\n",
    "Before running some Machine Learning models, we have to go through some preparation steps on the data, as\n",
    "- impute missing values\n",
    "- encode categorical variables (*gender*)\n",
    "- normalize feature distributions\n",
    "\n",
    "To do so, we use the classical **scikit-learn** API and the **SKLearnProcessor** feature of AWS Sagemaker to run the job on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bogo\n",
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-01-12-18-15-35-216\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/Capstone_Starbucks/bogo.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-15-35-216/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'bogo_data', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-15-35-216/output/bogo_data', 'LocalPath': '/opt/ml/processing/output/', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..................\n",
      "\u001b[34mCollecting joblib\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: joblib\u001b[0m\n",
      "\u001b[34mSuccessfully installed joblib-0.14.1\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "discount\n",
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-01-12-18-18-49-729\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/Capstone_Starbucks/discount.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-18-49-729/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'discount_data', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-18-49-729/output/discount_data', 'LocalPath': '/opt/ml/processing/output/', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..................\n",
      "\u001b[34mCollecting joblib\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: joblib\u001b[0m\n",
      "\u001b[34mSuccessfully installed joblib-0.14.1\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "info\n",
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-01-12-18-22-04-732\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/Capstone_Starbucks/info.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-22-04-732/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'info_data', 'S3Output': {'S3Uri': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-22-04-732/output/info_data', 'LocalPath': '/opt/ml/processing/output/', 'S3UploadMode': 'EndOfJob'}}]\n",
      ".................\u001b[34mCollecting joblib\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: joblib\u001b[0m\n",
      "\u001b[34mSuccessfully installed joblib-0.14.1\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "output_configs = {}\n",
    "\n",
    "for tgt in ['bogo', 'discount', 'info']:\n",
    "    print(tgt)\n",
    "    \n",
    "    sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                         role=role,\n",
    "                                         instance_type='ml.m5.xlarge',\n",
    "                                         instance_count=1)\n",
    "    sklearn_processor.run(\n",
    "        code='lib/preprocessing.py', #entrypoint for processing\n",
    "        inputs=[ProcessingInput(os.path.join('s3://', bucket, f'Capstone_Starbucks/{tgt}.csv'), '/opt/ml/processing/input')],\n",
    "        outputs=[\n",
    "            ProcessingOutput(source=f'/opt/ml/processing/output/',\n",
    "                             output_name=f'{tgt}_data')\n",
    "        ],\n",
    "        arguments=['--target', tgt]\n",
    "     )\n",
    "\n",
    "    preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "    output_configs[tgt] = preprocessing_job_description['ProcessingOutputConfig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bogo': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-15-35-216/output/bogo_data',\n",
       " 'discount': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-18-49-729/output/discount_data',\n",
       " 'info': 's3://sagemaker-eu-central-1-601949536922/sagemaker-scikit-learn-2020-01-12-18-22-04-732/output/info_data'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data = {}\n",
    "for output in output_configs:\n",
    "            preprocessed_data[output] = output_configs[output]['Outputs'][0]['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "for k in preprocessed_data:\n",
    "    for f in ['train.csv', 'val.csv', 'test.csv', 'transformer.joblib']:\n",
    "        copy_source = {'Bucket': bucket, 'Key': '/'.join(preprocessed_data[k][5:].split('/')[1:] + [f'{k}_{f}'])}\n",
    "        s3_client.copy_object(CopySource=copy_source, Bucket=bucket, Key=f'Capstone_Starbucks/{k}/{k}_{f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Machine Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'bogo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(session.boto_region_name, 'xgboost', '0.90-1')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role,\n",
    "                                    train_instance_count=1,\n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/Capstone_Starbucks/{}/model'.format(bucket, prefix),\n",
    "                                    sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning the hyperparameter tuning, we should make sure to set any model specific hyperparameters that we wish to have default values. There are quite a few that can be set when using the XGBoost algorithm, below are just a few of them. If you would like to change the hyperparameters below or modify additional ones you can find additional information on the [XGBoost hyperparameter page](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(objective='binary:logistic',\n",
    "                        max_depth=4,\n",
    "                        eta=0.1,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        colsample_bytree=0.5,\n",
    "                        subsample=0.6,\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200,\n",
    "                        seed=1123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our estimator object completely set up, it is time to create the hyperparameter tuner. To do this we need to construct a new object which contains each of the parameters we want SageMaker to tune. In this case, we wish to find the best values for the `max_depth`, `eta`, `min_child_weight`, `subsample`, and `gamma` parameters. Note that for each parameter that we want SageMaker to tune we need to specify both the *type* of the parameter and the *range* of values that parameter may take on.\n",
    "\n",
    "In addition, we specify the *number* of models to construct (`max_jobs`) and the number of those that can be trained in parallel (`max_parallel_jobs`). In the cell below we have chosen to train `20` models, of which we ask that SageMaker train `3` at a time in parallel. Note that this results in a total of `20` training jobs being executed which can take some time, in this case almost a half hour. With more complicated models this can take even longer so be aware!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator=xgb,\n",
    "                                               objective_metric_name='validation:error',\n",
    "                                               objective_type='Minimize',\n",
    "                                               max_jobs=20,\n",
    "                                               max_parallel_jobs=4,\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(2, 6),\n",
    "                                                    'eta'      : ContinuousParameter(0.01, 0.5),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'colsample_bytree': ContinuousParameter(0.2, 1.0),\n",
    "                                                    'subsample': ContinuousParameter(0.3, 1.0),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our hyperparameter tuner object completely set up, it is time to train it. To do this we make sure that SageMaker knows our input data is in csv format and then execute the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "s3_input_train = sagemaker.s3_input(s3_data=f's3://{bucket}/Capstone_Starbucks/{prefix}/{prefix}_train.csv', content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=f's3://{bucket}/Capstone_Starbucks/{prefix}/{prefix}_val.csv', content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in many of the examples we have seen so far, the `fit()` method takes care of setting up and fitting a number of different models, each with different hyperparameters. If we wish to wait for this process to finish, we can call the `wait()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-xgboost-191110-1613-016-cbc69477'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, since we'd like to set up a batch transform job to test the best model, we can construct a new estimator object from the results of the best training job. The `xgb_attached` object below can now be used as though we constructed an estimator with the best performing hyperparameters and then fit it to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-12 18:49:24 Starting - Preparing the instances for training\n",
      "2020-01-12 18:49:24 Downloading - Downloading input data\n",
      "2020-01-12 18:49:24 Training - Training image download completed. Training in progress.\n",
      "2020-01-12 18:49:24 Uploading - Uploading generated training model\n",
      "2020-01-12 18:49:24 Completed - Training job completed\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter _tuning_objective_metric value validation:error to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[18:49:13] 19663x15 matrix with 290405 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[18:49:13] 7786x15 matrix with 113325 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Setting up HPO optimized metric to be : error\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 19663 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 7786 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.388191#011validation-error:0.280118\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.386106#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.386055#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.386055#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.386055#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.388191#011validation-error:0.280118\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.388191#011validation-error:0.280118\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.388191#011validation-error:0.280118\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.386055#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.386055#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.386055#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.386055#011validation-error:0.274852\u001b[0m\n",
      "Training seconds: 55\n",
      "Billable seconds: 55\n"
     ]
    }
   ],
   "source": [
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aws] *",
   "language": "python",
   "name": "conda-env-aws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
